{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load necessary modules\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyn1x/software/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#load mnist dataset\n",
    "mnist = input_data.read_data_sets(\"mnist_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('size of training set:', (55000, 784))\n"
     ]
    }
   ],
   "source": [
    "#a glips of how the dataset looks like\n",
    "print(\"size of training set:\",mnist.train.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('size of test set', (10000, 784))\n"
     ]
    }
   ],
   "source": [
    "print(\"size of test set\", mnist.test.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define some global variables\n",
    "image_flat_size = mnist.train.images.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_shape = (28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, 6, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check labels\n",
    "mnist.train.labels[:5].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot iamges with labels\n",
    "\n",
    "def plot_images(images, real_labels, pre_labels=None):\n",
    "    assert len(images) == len(real_labels) == 9\n",
    "    \n",
    "    #creat a 3x3 canvas with subplots\n",
    "    fig, axes = plt.subplots(3,3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i].reshape((28,28)), cmap=\"binary\")\n",
    "    \n",
    "        if pre_labels is None:\n",
    "            xlabel = \"True: {0}\".format(real_labels[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Predict{1}\".format(real_label[i], pre_labels[i])\n",
    "        \n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        #remove ticks from the plot\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test plot function\n",
    "plot_images(mnist.train.images[:9],mnist.train.labels[:9].argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define placeholders(inputs)\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_real = tf.placeholder(tf.float32, [None, 10])\n",
    "y_real_labels = tf.placeholder(tf.int64,[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define model variables, difference between get_variable and Variable,\n",
    "#see:https://stackoverflow.com/questions/37098546/difference-between-variable-and-get-variable-in-tensorflow\n",
    "W = tf.get_variable(name=\"weights\", shape=[784,10], dtype=tf.float32)\n",
    "b = tf.get_variable(name=\"bias\", shape=[10], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct the model \n",
    "logits = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_labels_onehot = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_labels = tf.argmax(pre_labels_onehot,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cost function\n",
    "cross_entropy_loss = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels=y_real)\n",
    "cost = tf.reduce_mean(cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#choose an optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#performance measure\n",
    "correct_prediction = tf.equal(y_real_labels, pre_labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create data_batchs\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_batch(batch_size=batch_size):\n",
    "    idx = np.arange(mnist.train.num_examples)\n",
    "    np.random.shuffle(idx)\n",
    "    start = 0\n",
    "    end = start + batch_size\n",
    "    has_next_batch = True\n",
    "    \n",
    "    while(has_next_batch):\n",
    "        data_idx = idx[start:end]\n",
    "        next_batch_images = mnist.train.images[data_idx]\n",
    "        next_batch_labels = mnist.train.labels[data_idx]\n",
    "        start += batch_size\n",
    "        end += batch_size\n",
    "        yield (next_batch_images,next_batch_labels)\n",
    "        if end >= mnist.train.num_examples:\n",
    "            has_next_batch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_iteration = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1375\n",
      "0.1603\n",
      "0.2031\n",
      "0.2227\n",
      "0.2553\n",
      "0.2898\n",
      "0.3269\n",
      "0.3629\n",
      "0.3938\n",
      "0.4281\n",
      "0.4683\n",
      "0.4784\n",
      "0.5119\n",
      "0.5518\n",
      "0.5568\n",
      "0.5622\n",
      "0.59\n",
      "0.604\n",
      "0.607\n",
      "0.6115\n",
      "0.6395\n",
      "0.6496\n",
      "0.6586\n",
      "0.6693\n",
      "0.6567\n",
      "0.6759\n",
      "0.694\n",
      "0.7019\n",
      "0.7025\n",
      "0.712\n",
      "0.722\n",
      "0.7207\n",
      "0.7246\n",
      "0.7311\n",
      "0.7366\n",
      "0.744\n",
      "0.7415\n",
      "0.7394\n",
      "0.7457\n",
      "0.7538\n",
      "0.742\n",
      "0.7577\n",
      "0.7593\n",
      "0.7629\n",
      "0.764\n",
      "0.7661\n",
      "0.767\n",
      "0.7718\n",
      "0.7802\n",
      "0.7828\n",
      "0.7847\n",
      "0.7854\n",
      "0.7887\n",
      "0.7882\n",
      "0.7908\n",
      "0.795\n",
      "0.7955\n",
      "0.7951\n",
      "0.7961\n",
      "0.7945\n",
      "0.7922\n",
      "0.7929\n",
      "0.793\n",
      "0.793\n",
      "0.7945\n",
      "0.7953\n",
      "0.7985\n",
      "0.8019\n",
      "0.8086\n",
      "0.811\n",
      "0.8116\n",
      "0.8144\n",
      "0.8151\n",
      "0.8171\n",
      "0.8168\n",
      "0.8169\n",
      "0.82\n",
      "0.819\n",
      "0.8167\n",
      "0.8184\n",
      "0.8199\n",
      "0.8217\n",
      "0.8246\n",
      "0.8229\n",
      "0.8281\n",
      "0.8301\n",
      "0.827\n",
      "0.828\n",
      "0.8272\n",
      "0.8277\n",
      "0.83\n",
      "0.8295\n",
      "0.8305\n",
      "0.8334\n",
      "0.8345\n",
      "0.8341\n",
      "0.8338\n",
      "0.8355\n",
      "0.8348\n",
      "0.8333\n",
      "0.8369\n",
      "0.84\n",
      "0.8388\n",
      "0.8389\n",
      "0.8362\n",
      "0.8377\n",
      "0.836\n",
      "0.8355\n",
      "0.8356\n",
      "0.838\n",
      "0.8391\n",
      "0.8418\n",
      "0.8431\n",
      "0.8423\n",
      "0.8424\n",
      "0.84\n",
      "0.8429\n",
      "0.8417\n",
      "0.8405\n",
      "0.8419\n",
      "0.843\n",
      "0.8441\n",
      "0.844\n",
      "0.8468\n",
      "0.8467\n",
      "0.8481\n",
      "0.8483\n",
      "0.8485\n",
      "0.8489\n",
      "0.8456\n",
      "0.8457\n",
      "0.8484\n",
      "0.8487\n",
      "0.8471\n",
      "0.8485\n",
      "0.8526\n",
      "0.8496\n",
      "0.85\n",
      "0.8498\n",
      "0.8512\n",
      "0.8515\n",
      "0.85\n",
      "0.8497\n",
      "0.8507\n",
      "0.8497\n",
      "0.853\n",
      "0.8521\n",
      "0.8551\n",
      "0.8561\n",
      "0.856\n",
      "0.8546\n",
      "0.855\n",
      "0.8567\n",
      "0.855\n",
      "0.8569\n",
      "0.8584\n",
      "0.8556\n",
      "0.8556\n",
      "0.8589\n",
      "0.8599\n",
      "0.8595\n",
      "0.8601\n",
      "0.8608\n",
      "0.8611\n",
      "0.8627\n",
      "0.8624\n",
      "0.863\n",
      "0.8593\n",
      "0.8595\n",
      "0.8589\n",
      "0.8589\n",
      "0.8607\n",
      "0.863\n",
      "0.861\n",
      "0.8604\n",
      "0.8569\n",
      "0.8586\n",
      "0.8602\n",
      "0.8592\n",
      "0.859\n",
      "0.8592\n",
      "0.86\n",
      "0.8614\n",
      "0.861\n",
      "0.8605\n",
      "0.862\n",
      "0.8628\n",
      "0.8623\n",
      "0.8621\n",
      "0.864\n",
      "0.8641\n",
      "0.8621\n",
      "0.8623\n",
      "0.8642\n",
      "0.8648\n",
      "0.8648\n",
      "0.8657\n",
      "0.8663\n",
      "0.8645\n",
      "0.8628\n",
      "0.8615\n",
      "0.8636\n",
      "0.8641\n",
      "0.8642\n",
      "0.8655\n",
      "0.8632\n",
      "0.8642\n",
      "0.864\n",
      "0.863\n",
      "0.8624\n",
      "0.864\n",
      "0.8657\n",
      "0.8654\n",
      "0.8651\n",
      "0.8669\n",
      "0.8666\n",
      "0.8672\n",
      "0.8666\n",
      "0.8668\n",
      "0.8661\n",
      "0.8663\n",
      "0.8667\n",
      "0.8656\n",
      "0.8682\n",
      "0.8693\n",
      "0.8693\n",
      "0.8683\n",
      "0.8685\n",
      "0.8671\n",
      "0.8686\n",
      "0.8697\n",
      "0.8689\n",
      "0.8693\n",
      "0.8713\n",
      "0.8689\n",
      "0.87\n",
      "0.8711\n",
      "0.8716\n",
      "0.8709\n",
      "0.8707\n",
      "0.8702\n",
      "0.8719\n",
      "0.8717\n",
      "0.8716\n",
      "0.8713\n",
      "0.8705\n",
      "0.8719\n",
      "0.8706\n",
      "0.8687\n",
      "0.8695\n",
      "0.871\n",
      "0.8712\n",
      "0.8715\n",
      "0.8721\n",
      "0.8718\n",
      "0.8719\n",
      "0.8736\n",
      "0.874\n",
      "0.8698\n",
      "0.8693\n",
      "0.8713\n",
      "0.8725\n",
      "0.8719\n",
      "0.873\n",
      "0.8721\n",
      "0.8731\n",
      "0.8728\n",
      "0.8732\n",
      "0.874\n",
      "0.8739\n",
      "0.8731\n",
      "0.8741\n",
      "0.8736\n",
      "0.8741\n",
      "0.8751\n",
      "0.8763\n",
      "0.8769\n",
      "0.8759\n",
      "0.8764\n",
      "0.8763\n",
      "0.8779\n",
      "0.8777\n",
      "0.8773\n",
      "0.8783\n",
      "0.8779\n",
      "0.8776\n",
      "0.8782\n",
      "0.8774\n",
      "0.878\n",
      "0.877\n",
      "0.8767\n",
      "0.8774\n",
      "0.8775\n",
      "0.8768\n",
      "0.8759\n",
      "0.876\n",
      "0.876\n",
      "0.8772\n",
      "0.8778\n",
      "0.8788\n",
      "0.8783\n",
      "0.8779\n",
      "0.8786\n",
      "0.8787\n",
      "0.879\n",
      "0.8798\n",
      "0.8797\n",
      "0.8784\n",
      "0.878\n",
      "0.8787\n",
      "0.8786\n",
      "0.8776\n",
      "0.8782\n",
      "0.8769\n",
      "0.877\n",
      "0.8777\n",
      "0.8767\n",
      "0.8773\n",
      "0.8794\n",
      "0.8787\n",
      "0.8782\n",
      "0.8785\n",
      "0.8799\n",
      "0.8799\n",
      "0.8797\n",
      "0.8809\n",
      "0.8806\n",
      "0.8809\n",
      "0.879\n",
      "0.8802\n",
      "0.8799\n",
      "0.8801\n",
      "0.8797\n",
      "0.8799\n",
      "0.8797\n",
      "0.8799\n",
      "0.8795\n",
      "0.8795\n",
      "0.8808\n",
      "0.8805\n",
      "0.8809\n",
      "0.8811\n",
      "0.8812\n",
      "0.8804\n",
      "0.8805\n",
      "0.8808\n",
      "0.8795\n",
      "0.881\n",
      "0.8801\n",
      "0.8793\n",
      "0.8783\n",
      "0.8775\n",
      "0.8794\n",
      "0.8794\n",
      "0.88\n",
      "0.881\n",
      "0.8816\n",
      "0.8818\n",
      "0.8814\n",
      "0.8827\n",
      "0.8821\n",
      "0.8825\n",
      "0.8824\n",
      "0.8823\n",
      "0.8815\n",
      "0.881\n",
      "0.8802\n",
      "0.8806\n",
      "0.8805\n",
      "0.8815\n",
      "0.8819\n",
      "0.8818\n",
      "0.8815\n",
      "0.8818\n",
      "0.8813\n",
      "0.8811\n",
      "0.8808\n",
      "0.8815\n",
      "0.8814\n",
      "0.8812\n",
      "0.8813\n",
      "0.8806\n",
      "0.8815\n",
      "0.8815\n",
      "0.8813\n",
      "0.8803\n",
      "0.8826\n",
      "0.8827\n",
      "0.8823\n",
      "0.8829\n",
      "0.8845\n",
      "0.8846\n",
      "0.8843\n",
      "0.8844\n",
      "0.8838\n",
      "0.8834\n",
      "0.8837\n",
      "0.883\n",
      "0.8827\n",
      "0.8831\n",
      "0.8838\n",
      "0.8838\n",
      "0.8822\n",
      "0.8827\n",
      "0.8835\n",
      "0.8854\n",
      "0.884\n",
      "0.8846\n",
      "0.8849\n",
      "0.8839\n",
      "0.885\n",
      "0.8849\n",
      "0.8844\n",
      "0.8853\n",
      "0.8845\n",
      "0.8857\n",
      "0.8848\n",
      "0.8851\n",
      "0.885\n",
      "0.8859\n",
      "0.8846\n",
      "0.885\n",
      "0.8844\n",
      "0.8854\n",
      "0.8847\n",
      "0.8849\n",
      "0.8845\n",
      "0.8836\n",
      "0.8835\n",
      "0.8846\n",
      "0.8857\n",
      "0.8848\n",
      "0.8847\n",
      "0.8854\n",
      "0.8847\n",
      "0.8858\n",
      "0.8853\n",
      "0.8862\n",
      "0.8849\n",
      "0.8855\n",
      "0.8851\n",
      "0.8852\n",
      "0.8853\n",
      "0.8856\n",
      "0.8861\n",
      "0.8866\n",
      "0.8879\n",
      "0.8877\n",
      "0.888\n",
      "0.8875\n",
      "0.8874\n",
      "0.8861\n",
      "0.8867\n",
      "0.8862\n",
      "0.8883\n",
      "0.8868\n",
      "0.886\n",
      "0.8858\n",
      "0.8853\n",
      "0.8872\n",
      "0.8877\n",
      "0.888\n",
      "0.8875\n",
      "0.8875\n",
      "0.8878\n",
      "0.8878\n",
      "0.8878\n",
      "0.887\n",
      "0.8875\n",
      "0.8871\n",
      "0.8873\n",
      "0.8861\n",
      "0.8869\n",
      "0.8868\n",
      "0.8877\n",
      "0.8881\n",
      "0.8872\n",
      "0.8858\n",
      "0.887\n",
      "0.8879\n",
      "0.8873\n",
      "0.8885\n",
      "0.8882\n",
      "0.8882\n",
      "0.8882\n",
      "0.8877\n",
      "0.8884\n",
      "0.889\n",
      "0.8885\n",
      "0.8876\n",
      "0.8876\n",
      "0.888\n",
      "0.8886\n",
      "0.889\n",
      "0.8883\n",
      "0.8876\n",
      "0.8876\n",
      "0.8888\n",
      "0.8881\n",
      "0.8868\n"
     ]
    }
   ],
   "source": [
    "#build the session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    assert num_iteration < 550\n",
    "    for i in range(num_iteration):\n",
    "        input_data = get_next_batch()\n",
    "        x_batch, y_batch = input_data.next()\n",
    "        #print(x.dtype, x_batch.dtype, y_real.dtype, y_batch.dtype)\n",
    "        feed_dict = {x:x_batch, y_real:y_batch}\n",
    "        sess.run(optimizer, feed_dict = feed_dict)\n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, \\\n",
    "                                        y_real:mnist.test.labels, \\\n",
    "                                        y_real_labels:np.argmax(mnist.test.labels,axis=1)})\n",
    "        print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize(num_iteration):\n",
    "    for i in range(num_iteration):\n",
    "        x_batch, y_batch = mnist.train.next_batch(100)\n",
    "        feed_dict_train = {x:x_batch, y_real:y_batch}\n",
    "        sess.run(optimizer, feed_dict=feed_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimize(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_acc():\n",
    "    acc = sess.run(accuracy, feed_dict={x:mnist.test.images, \\\n",
    "                                        y_real:mnist.test.labels, \\\n",
    "                                        y_real_labels:np.argmax(mnist.test.labels,axis=1)})\n",
    "    print(\"accuracy on testset: {0:.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testset: 12.85%\n"
     ]
    }
   ],
   "source": [
    "print_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix():\n",
    "    real_labels = np.argmax(mnist.test.labels, axis=1)\n",
    "    pred_labels = sess.run(pre_labels, feed_dict={x:mnist.test.images, \\\n",
    "                                                   y_real:mnist.test.labels})\n",
    "    #print(real_labels, pred_labels)\n",
    "    confusion_mat = confusion_matrix(y_true=real_labels, y_pred=pred_labels)\n",
    "    print(confusion_mat)\n",
    "    plt.imshow(confusion_mat, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('predict')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[286   0 263   0   0 120  41 243  24   3]\n",
      " [ 55   0 368   2   0 115  17 578   0   0]\n",
      " [330   1 313   6   2  71  20 232  38  19]\n",
      " [169   1 657   0   3  31  45  96   4   4]\n",
      " [188  32 164  75   4  92   8 224 110  85]\n",
      " [274  12 404   0   3  35  53 107   3   1]\n",
      " [312  20 192   4  19  31 112 141  78  49]\n",
      " [ 57   3 340  27   0  62   7 475  14  43]\n",
      " [203   0 358   0   6  74  44 262  11  16]\n",
      " [201  10 252  18   0  34   8 420  17  49]]\n"
     ]
    }
   ],
   "source": [
    "print_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_example_errors():"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
